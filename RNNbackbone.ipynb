{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from CFN_impl import CFNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFNCell(tf.keras.layers.AbstractRNNCell):\n",
    "    def __init__(self, num_units, **kwargs) -> None:\n",
    "        super(CFNCell,self).__init__(**kwargs)\n",
    "        self._num_units = num_units\n",
    "        # self.state_size = tf.TensorShape([num_units])\n",
    "        # self.output_size = tf.TensorShape([num_units])\n",
    "        self._activation = tf.keras.activations.tanh\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "      return self._num_units\n",
    "\n",
    "    def build(self, inputs_shape):\n",
    "        #super().build(inputs_shape)\n",
    "        self._weights_U_theta = self.add_weight(\n",
    "            \"gate/U_theta\",\n",
    "            shape=(self._num_units, self._num_units),\n",
    "            initializer=tf.keras.initializers.RandomUniform(minval=-0.07,maxval=0.07),\n",
    "            trainable=True   #\n",
    "            )\n",
    "    \n",
    "        self._weights_V_theta = self.add_weight(\n",
    "            \"gate/V_theta\",\n",
    "            shape=(inputs_shape[-1], self._num_units),\n",
    "            initializer=tf.keras.initializers.RandomUniform(minval=-0.07,maxval=0.07),   ##tf.random_uniform_initializer(dtype = self.dtype, minval=-0.07,maxval=0.07)\n",
    "            trainable=True\n",
    "            )\n",
    "        \n",
    "        self._bias_theta = self.add_weight(\n",
    "            \"gate/b_theta\",\n",
    "            shape=(self._num_units),\n",
    "            initializer= tf.keras.initializers.Constant(value=1), ##tf.ones_initializer(dtype=self.dtype))\n",
    "            trainable=True\n",
    "            )\n",
    "        \n",
    "        self._weights_U_n = self.add_weight(\n",
    "            \"gate/U_n\",\n",
    "            shape=(self._num_units, self._num_units),\n",
    "            initializer=tf.keras.initializers.RandomUniform(minval=-0.07,maxval=0.07),\n",
    "            trainable=True\n",
    "            )\n",
    "        \n",
    "        self._weights_V_n = self.add_weight(\n",
    "            \"gate/V_n\",\n",
    "            shape=(inputs_shape[-1], self._num_units),\n",
    "            initializer=tf.keras.initializers.RandomUniform(minval=-0.07,maxval=0.07),\n",
    "            trainable=True\n",
    "            )\n",
    "        \n",
    "        self._bias_n = self.add_weight(\n",
    "            \"gate/b_n\",\n",
    "            shape=(self._num_units),\n",
    "            initializer= tf.keras.initializers.Constant(value=-1), ##MinusOnes(dtype=self.dtype)\n",
    "            trainable=True\n",
    "            )\n",
    "        self._W =  self.add_weight(\n",
    "            \"kernel\",\n",
    "            shape=(inputs_shape[-1], self._num_units),\n",
    "            initializer=tf.keras.initializers.RandomUniform(minval=-0.07,maxval=0.07),\n",
    "            trainable=True\n",
    "            )\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, state):\n",
    "        states=state[0]\n",
    "        theta = tf.keras.activations.sigmoid(\n",
    "            tf.add(tf.add(tf.matmul(states, self._weights_U_theta),\n",
    "                    tf.matmul(inputs, self._weights_V_theta)),\n",
    "                    self._bias_theta)\n",
    "        )\n",
    "        eta = tf.keras.activations.sigmoid(\n",
    "            tf.add(tf.add(tf.matmul(states, self._weights_U_n),\n",
    "                    tf.matmul(inputs, self._weights_V_n)),\n",
    "                    self._bias_n)\n",
    "        )\n",
    "        output = tf.add(\n",
    "                    tf.math.multiply(theta, self._activation(states)),\n",
    "                    tf.math.multiply(eta, self._activation(tf.matmul(inputs, self._W)))\n",
    "        )\n",
    "        return output ,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfncell = CFNCell(64)\n",
    "lstmcell = tf.keras.layers.LSTMCell\n",
    "lstmlayer = tf.keras.layers.RNN(lstmcell(32), return_state=True)\n",
    "cfnlayer = tf.keras.layers.RNN(cfncell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 64)     64000       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 64)     128000      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " encoder (RNN)                  [(None, 64),         20608       ['embedding[0][0]']              \n",
      "                                 (None, 64)]                                                      \n",
      "                                                                                                  \n",
      " decoder (RNN)                  (None, 64)           20608       ['embedding_1[0][0]',            \n",
      "                                                                  'encoder[0][1]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           650         ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 233,866\n",
      "Trainable params: 233,866\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 10:03:00.991001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-12 10:03:01.026629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-12 10:03:01.026709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-12 10:03:01.027227: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-12 10:03:01.028100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-12 10:03:01.028161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-12 10:03:01.028204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-12 10:03:01.394687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-12 10:03:01.394775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-12 10:03:01.394825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-12 10:03:01.395020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5988 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "encoder_vocab = 1000\n",
    "decoder_vocab = 2000\n",
    "\n",
    "encoder_input = layers.Input(shape=(None,))\n",
    "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(\n",
    "    encoder_input\n",
    ")\n",
    "\n",
    "# Return states in addition to output\n",
    "encoderlayer = tf.keras.layers.RNN(CFNCell(64),return_state=True, name=\"encoder\")\n",
    "output, encoder_state = encoderlayer(\n",
    "    encoder_embedded\n",
    ")\n",
    "#encoder_state = [state_h, state_c]\n",
    "\n",
    "decoder_input = layers.Input(shape=(None,))\n",
    "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(\n",
    "    decoder_input\n",
    ")\n",
    "decoderlayer = tf.keras.layers.RNN(CFNCell(64), name=\"decoder\")\n",
    "# Pass the 2 states to a new LSTM layer, as initial state\n",
    "decoder_output = decoderlayer(\n",
    "    decoder_embedded, initial_state=encoder_state\n",
    ")\n",
    "output = layers.Dense(10)(decoder_output)\n",
    "\n",
    "model = keras.Model([encoder_input, decoder_input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedCell(keras.layers.Layer):\n",
    "    def __init__(self, unit_1, unit_2, unit_3, **kwargs):\n",
    "        self.unit_1 = unit_1\n",
    "        self.unit_2 = unit_2\n",
    "        self.unit_3 = unit_3\n",
    "        self.state_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
    "        self.output_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
    "        super(NestedCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        # expect input_shape to contain 2 items, [(batch, i1), (batch, i2, i3)]\n",
    "        i1 = input_shapes[0][1]\n",
    "        i2 = input_shapes[1][1]\n",
    "        i3 = input_shapes[1][2]\n",
    "\n",
    "        self.kernel_1 = self.add_weight(\n",
    "            shape=(i1, self.unit_1), initializer=\"uniform\", name=\"kernel_1\"\n",
    "        )\n",
    "        self.kernel_2_3 = self.add_weight(\n",
    "            shape=(i2, i3, self.unit_2, self.unit_3),\n",
    "            initializer=\"uniform\",\n",
    "            name=\"kernel_2_3\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        # inputs should be in [(batch, input_1), (batch, input_2, input_3)]\n",
    "        # state should be in shape [(batch, unit_1), (batch, unit_2, unit_3)]\n",
    "        input_1, input_2 = tf.nest.flatten(inputs)\n",
    "        s1, s2 = states\n",
    "\n",
    "        output_1 = tf.matmul(input_1, self.kernel_1)\n",
    "        output_2_3 = tf.einsum(\"bij,ijkl->bkl\", input_2, self.kernel_2_3)\n",
    "        state_1 = s1 + output_1\n",
    "        state_2_3 = s2 + output_2_3\n",
    "\n",
    "        output = (output_1, output_2_3)\n",
    "        new_states = (state_1, state_2_3)\n",
    "\n",
    "        return output, new_states\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"unit_1\": self.unit_1, \"unit_2\": unit_2, \"unit_3\": self.unit_3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_1 = 10\n",
    "unit_2 = 20\n",
    "unit_3 = 30\n",
    "\n",
    "i1 = 32\n",
    "i2 = 64\n",
    "i3 = 32\n",
    "batch_size = 64\n",
    "num_batches = 10\n",
    "timestep = 50\n",
    "\n",
    "cell = NestedCell(unit_1, unit_2, unit_3)\n",
    "rnn = keras.layers.RNN(cell)\n",
    "\n",
    "input_1 = keras.Input((None, i1))\n",
    "input_2 = keras.Input((None, i2, i3))\n",
    "\n",
    "outputs = rnn((input_1, input_2))\n",
    "\n",
    "model = keras.models.Model([input_1, input_2], outputs)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, None, 32)]   0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, None, 64, 3  0           []                               \n",
      "                                2)]                                                               \n",
      "                                                                                                  \n",
      " rnn_4 (RNN)                    ((None, 10),         1229120     ['input_8[0][0]',                \n",
      "                                 (None, 20, 30))                  'input_9[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,229,120\n",
      "Trainable params: 1,229,120\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 11ms/step - loss: 0.7165 - rnn_4_loss: 0.2398 - rnn_4_1_loss: 0.4767 - rnn_4_accuracy: 0.0875 - rnn_4_1_accuracy: 0.0309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 15:02:30.917232: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd53afb4ee0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1_data = np.random.random((batch_size * num_batches, timestep, i1))\n",
    "input_2_data = np.random.random((batch_size * num_batches, timestep, i2, i3))\n",
    "target_1_data = np.random.random((batch_size * num_batches, unit_1))\n",
    "target_2_data = np.random.random((batch_size * num_batches, unit_2, unit_3))\n",
    "input_data = [input_1_data, input_2_data]\n",
    "target_data = [target_1_data, target_2_data]\n",
    "\n",
    "model.fit(input_data, target_data, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
